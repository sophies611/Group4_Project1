---
title: "Project1"
author: "Sophie Shao, Sophia Yang, Han (Andy) Xu, Ken Bai, Shenyi (Elaine) Ge"
date: "10/6/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Telemarketing Project

## Downloading and Prepping the Data
```{r}
# Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)

# We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call.
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL

str(tele)
```

## Getting Data Ready for Analysis
```{r, cache=TRUE}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))
str(telemm)

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# We are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))
```

## Getting Train and Test Samples
```{r}
# Selects 10000 random rows for test data
set.seed(12345)
test_set <- sample(1:nrow(tele_norm), 10000)
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

# Create a train set and test set
# First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, -match("yyes",names(tele_norm))]
tele_test <- tele_norm[test_set, -match("yyes",names(tele_norm))]

# Now the response (aka Labels) - only the yyes column
tele_train_labels <- tele_norm[-test_set, "yyes"]
tele_test_labels <- tele_norm[test_set, "yyes"]
summary(tele_train)
```

## Import Libraries
```{r}
library(neuralnet)
library(gmodels)
library(caret)
library(class)
threshold <- 0.6
```

## Clustering
```{r}
set.seed(123)

tele_norm_cluster <- tele_norm[, -match("yyes",names(tele_norm))]

tele_clusters <- kmeans(tele_norm_cluster, 5)

## Evaluating model performance
# Look at the size of the clusters
tele_clusters$size

# Look at the cluster centers
tele_clusters$centers
tele_clusters$cluster

tele_norm_cluster$cluster <- tele_clusters$cluster
tele_norm_cluster$yyes <- tele_norm$yyes

tapply(tele_norm_cluster$yyes, tele_norm_cluster$cluster, mean)
aggregate(data=tele_norm_cluster, yyes~cluster, mean)

# Create 4 datasets
cluster_1 <- tele_norm_cluster[tele_norm_cluster$cluster==1,]
cluster_2 <- tele_norm_cluster[tele_norm_cluster$cluster==2,]
cluster_3 <- tele_norm_cluster[tele_norm_cluster$cluster==3,]
cluster_4 <- tele_norm_cluster[tele_norm_cluster$cluster==4,]
cluster_5 <- tele_norm_cluster[tele_norm_cluster$cluster==5,]
```

### Cluster 1

Since Cluster 1 yielded the highest call acceptance rate, we will run our models on the other 4 clusters. 

### Cluster 2
```{r, cache=TRUE}
set.seed(12345)
test_set2 <- sample(1:nrow(cluster_2), 2500)
tele_train_labels_2 <- cluster_2[-test_set2, "yyes"]
tele_test_labels_2 <- cluster_2[test_set2, "yyes"]
tele_train_2 <- cluster_2[-test_set2,]
tele_test_2 <- cluster_2[test_set2,]

#KNN
#teleknn_model2 <- knn(train = tele_train_2, test = tele_test_2, cl = tele_train_labels2, k = sqrt(nrow(tele_train_2)))
teleknn_model2_improved <- knn(train = tele_train_2, test = tele_test_2, cl = tele_train_labels_2, k = 5)
CrossTable(x = tele_test_labels_2, y = teleknn_model2_improved, prop.chisq = FALSE)
confusionMatrix(as.factor(teleknn_model2_improved), as.factor(tele_test_labels_2), positive = "1")

#ANN

tele_ann_train_2 <- cluster_2[-test_set2, ]
tele_ann_train_2$yyes <- ifelse(tele_ann_train_2$yyes > 0, .9, .1) #only for ANN & logistic
tele_ann_test_2 <- cluster_2[test_set2,-match("yyes",names(cluster_2))]

teleann_model_2 <- neuralnet(formula = yyes ~ ., data = tele_ann_train_2, hidden=c(2), threshold=0.01, stepmax=10^10, learningrate=0.001)
plot(teleann_model_2)
model_results <- compute(teleann_model_2, tele_ann_test_2)
predicted_strength <- model_results$net.result
model_results <- ifelse(predicted_strength>=threshold, 1,0) #convert thresholds
cor(predicted_strength, tele_test_labels_2)
CrossTable(x = tele_test_labels_2, y = model_results, prop.chisq = FALSE)
confusionMatrix(as.factor(model_results), as.factor(tele_test_labels_2), positive = "1")


#Logistic
tele_train_2$y <- tele_train_labels_2
tele_test_2$y <- tele_test_labels_2

tele_log_model_2 <- glm(y~.+ maritalmarried* housingyes + educationuniversity.degree*maritalmarried, data = tele_ann_train_2, family = "binomial")
predict_values_2 <- predict(tele_log_model_2, newdata=tele_ann_test_2, type="response")
modpred_2 <- as.factor(ifelse(predict_values_2 <= threshold, 0, 1))
CrossTable(x = tele_test_labels_2, y = modpred_2, prop.chisq=FALSE)
confusionMatrix(modpred_2, as.factor(tele_test_labels_2), positive = "1")


cluster_2_vote <- data.frame(teleknn_model2_improved, model_results, modpred_2)
```

### Cluster 3
```{r, cache=TRUE}
set.seed(12345)
test_set3 <- sample(1:nrow(cluster_3), 1500)
tele_train_labels_3 <- cluster_3[-test_set3, "yyes"]
tele_test_labels_3 <- cluster_3[test_set3, "yyes"]
tele_train_3 <- cluster_3[-test_set3,]
tele_test_3 <- cluster_3[test_set3,]

#KNN
#teleknn_model3 <- knn(train = tele_train_3, test = tele_test_3, cl = tele_train_labels_3, k = sqrt(nrow(tele_train_3)))
teleknn_model3_improved <- knn(train = tele_train_3, test = tele_test_3, cl = tele_train_labels_3, k = 5)
CrossTable(x = tele_test_labels_3, y = teleknn_model3_improved, prop.chisq = FALSE)
confusionMatrix(as.factor(teleknn_model3_improved), as.factor(tele_test_labels3), positive = "1")

#ANN

tele_ann_train_3 <- cluster_3[-test_set3, ]
tele_ann_train_3$yyes <- ifelse(tele_ann_train_3$yyes > 0, .9, .1) #only for ANN & logistic
teleann_test_3 <- cluster_3[test_set3,-match("yyes",names(cluster_3))]

teleann_model_3 <- neuralnet(formula = yyes ~ ., data = tele_ann_train_3, hidden=c(2), threshold=0.01, stepmax=10^10, learningrate=0.001)
plot(teleann_model_3)
model_results <- compute(teleann_model_3, teleann_test_3)
predicted_strength <- model_results$net.result
model_results <- ifelse(predicted_strength>=threshold, 1,0) #convert thresholds
cor(predicted_strength, tele_test_labels_3)
CrossTable(x = tele_test_labels_3, y = model_results, prop.chisq = FALSE)
confusionMatrix(as.factor(model_results), as.factor(tele_test_labels_3), positive = "1")


#Logistic
tele_train_3$y <- tele_train_labels_3
tele_test_3$y <- tele_test_labels_3

tele_log_model_3 <- glm(y~.+ maritalmarried* housingyes + educationuniversity.degree*maritalmarried, data = tele_ann_train_3, family = "binomial")
predict_values_3 <- predict(tele_log_model_3, newdata=teleann_test_3, type="response")
modpred_3 <- as.factor(ifelse(predict_values_3 <= threshold, 0, 1))
CrossTable(x = tele_test_labels_3, y = modpred_3, prop.chisq=FALSE)
confusionMatrix(modpred_3, as.factor(tele_test_labels_3), positive = "1")
```

### Cluster 4
```{r}
set.seed(12345)
test_set4 <- sample(1:nrow(cluster_4), 1500)
tele_train_labels_4 <- cluster_4[-test_set4, "yyes"]
tele_test_labels_4 <- cluster_4[test_set4, "yyes"]
tele_train_4 <- cluster_4[-test_set4,]
tele_test_4 <- cluster_4[test_set4,]

#KNN
#teleknn_model4 <- knn(train = tele_train_4, test = tele_test_4, cl = tele_train_labels_4, k = sqrt(nrow(tele_train_4)))
teleknn_model4_improved <- knn(train = tele_train_4, test = tele_test_4, cl = tele_train_labels_4, k = 1)
CrossTable(x = tele_test_labels_4, y = teleknn_model4_improved, prop.chisq = FALSE)
confusionMatrix(as.factor(teleknn_model4_improved), as.factor(tele_test_labels_4), positive = "1")


#ANN

tele_ann_train_4 <- cluster_4[-test_set4, ]
tele_ann_train_4$yyes <- ifelse(tele_ann_train_4$yyes > 0, .9, .1) #only for ANN & logistic
tele_ann_test_4 <- cluster_4[test_set4,-match("yyes",names(cluster_4))]

teleann_model_4 <- neuralnet(formula = yyes ~ ., data = tele_ann_train_4, hidden=c(2), threshold=0.01, stepmax=10^10, learningrate=0.001)
plot(teleann_model_4)
model_results <- compute(teleann_model_4, tele_ann_test_4)
predicted_strength <- model_results$net.result
model_results <- ifelse(predicted_strength>=threshold, 1,0) #convert thresholds
cor(predicted_strength, tele_test_labels_4)
CrossTable(x = tele_test_labels_4, y = model_results, prop.chisq = FALSE)
confusionMatrix(as.factor(model_results), as.factor(tele_test_labels_4), positive = "1")
#Logistic
tele_train_4$y <- tele_train_labels_4
tele_test_4$y <- tele_test_labels_4

tele_log_model_4 <- glm(y~.+ maritalmarried* housingyes + educationuniversity.degree*maritalmarried, data = tele_ann_train_4, family = "binomial")
predict_values_4 <- predict(tele_log_model_4, newdata=tele_ann_test_4, type="response")
modpred_4 <- as.factor(ifelse(predict_values_4 <= threshold, 0, 1))
CrossTable(x = tele_test_labels_4, y = modpred_4, prop.chisq=FALSE)
confusionMatrix(modpred_4, as.factor(tele_test_labels_4), positive = "1")
```

### Cluster 5
```{r}
set.seed(12345)
test_set5 <- sample(1:nrow(cluster_5), 2000)
tele_train_labels_5 <- cluster_5[-test_set5, "yyes"]
tele_test_labels_5 <- cluster_5[test_set5, "yyes"]
tele_train_5 <- cluster_5[-test_set5,]
tele_test_5 <- cluster_5[test_set5,]

#KNN
#teleknn_model5 <- knn(train = tele_train_5, test = tele_test_5, cl = tele_train_labels5, k = sqrt(nrow(tele_train_5)))
teleknn_model5_improved <- knn(train = tele_train_5, test = tele_test_5, cl = tele_train_labels_5, k = 1)
CrossTable(x = tele_test_labels_5, y = teleknn_model5_improved, prop.chisq = FALSE)
confusionMatrix(as.factor(teleknn_model5_improved), as.factor(tele_test_labels_5), positive = "1")


#ANN


tele_ann_train_5 <- cluster_5[-test_set5, ]
tele_ann_train_5$yyes <- ifelse(tele_ann_train_5$yyes > 0, .9, .1) #only for ANN & logistic
tele_ann_test_5 <- cluster_5[test_set5,-match("yyes",names(cluster_5))]

teleann_model_5 <- neuralnet(formula = yyes ~ ., data = tele_ann_train_5, hidden=c(2), threshold=0.01, stepmax=10^10, learningrate=0.001)
plot(teleann_model_5)
model_results <- compute(teleann_model_5, tele_ann_test_5)
predicted_strength <- model_results$net.result
model_results <- ifelse(predicted_strength>=threshold, 1,0) #convert thresholds
cor(predicted_strength, tele_test_labels_5)
CrossTable(x = tele_test_labels_5, y = model_results, prop.chisq = FALSE)
confusionMatrix(as.factor(model_results), as.factor(tele_test_labels_5), positive = "1")

#Logistic
tele_train_5$y <- tele_train_labels_5
tele_test_5$y <- tele_test_labels_5

tele_log_model_5 <- glm(y~.+ maritalmarried* housingyes + educationuniversity.degree*maritalmarried, data = tele_ann_train_5, family = "binomial")
predict_values_5 <- predict(tele_log_model_5, newdata=tele_ann_test_5, type="response")
modpred_5 <- as.factor(ifelse(predict_values_5 <= threshold, 0, 1))
CrossTable(x = tele_test_labels_5, y = modpred_5, prop.chisq=FALSE)
confusionMatrix(modpred_5, as.factor(tele_test_labels_5), positive = "1")
```


#Voting Model
```{r}





```


