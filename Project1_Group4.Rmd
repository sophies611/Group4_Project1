---
title: "Project1"
author: "Sophie Shao, Sophia Yang, Han (Andy) Xu, Ken Bai, Shenyi (Elaine) Ge"
date: "10/6/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Telemarketing Project

Objective and Method: For this project, we are using different regression models to predict whether the tele-marketing call will be successful or not. We created five clusters to identify subsets, and created and improved kNN, ANN and Logistic Regression models to derive the best-performing models. We then ran each model on the clusters for evaluation, as well as created a combined prediction using all three models using a majority voting scheme as an effort to predict the testing data and improve the prediction.


## Downloading and Prepping the Data


```{r}
# Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)

# We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call.
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL

str(tele)
```

## Getting Data Ready for Analysis

Here we are normalizing the data to improve the training process by turning our factor variables into numeric.
```{r, cache=TRUE}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))
str(telemm)

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# We are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))
```

## Getting Train and Test Samples

```{r}
# Selects 10000 random rows for test data
set.seed(12345)
test_set <- sample(1:nrow(tele_norm), 10000)
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

# Create a train set and test set
# First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, -match("yyes",names(tele_norm))]
tele_test <- tele_norm[test_set, -match("yyes",names(tele_norm))]

# Now the response (aka Labels) - only the yyes column
tele_train_labels <- tele_norm[-test_set, "yyes"]
tele_test_labels <- tele_norm[test_set, "yyes"]
summary(tele_train)
```

## Import Libraries
```{r}
library(neuralnet)
library(gmodels)
library(caret)
library(class)
threshold <- 0.6
```

## Clustering

We are using the clustering method to identify and group similar data points. This way we can identify subsets to focus on calling. We removed the outcome variable in the dataset so that the model doesn't overperform and groups based off of the predictor variables. 

```{r}
set.seed(123)


tele_norm_cluster <- tele_norm[, -match("yyes",names(tele_norm))]

tele_clusters <- kmeans(tele_norm_cluster, 5)

## Evaluating model performance
# Look at the size of the clusters
tele_clusters$size

# Look at the cluster centers
tele_clusters$centers
tele_clusters$cluster

tele_norm_cluster$cluster <- tele_clusters$cluster
tele_norm_cluster$yyes <- tele_norm$yyes

tapply(tele_norm_cluster$yyes, tele_norm_cluster$cluster, mean)
aggregate(data=tele_norm_cluster, yyes~cluster, mean)

# Create 4 datasets
cluster_1 <- tele_norm_cluster[tele_norm_cluster$cluster==1,]
cluster_2 <- tele_norm_cluster[tele_norm_cluster$cluster==2,]
cluster_3 <- tele_norm_cluster[tele_norm_cluster$cluster==3,]
cluster_4 <- tele_norm_cluster[tele_norm_cluster$cluster==4,]
cluster_5 <- tele_norm_cluster[tele_norm_cluster$cluster==5,]
```

### Cluster 1

```{r}
teleann_train <- tele_norm[-test_set,]
teleann_test <- tele_norm[test_set,-match("yyes",names(tele_norm))]
tele_train_labels <- tele_norm[-test_set, "yyes"]
tele_test_labels <- tele_norm[test_set, "yyes"]
teleann_model_1h <- neuralnet(formula = yyes ~ ., data = teleann_train, hidden=c(5,3), threshold=0.01)
plot(teleann_model)

model_results <- compute(teleann_model, teleann_test)
predicted_strength <- model_results$net.result
model_results <- ifelse(predicted_strength>=threshold, 1,0) #convert thresholds
cor(predicted_strength, tele_test_labels_2)
CrossTable(x = tele_test_labels, y = model_results, prop.chisq = FALSE)
confusionMatrix(as.factor(model_results), as.factor(tele_test_labels), positive = "1")
```


Since Cluster 1 yielded the highest call acceptance rate, we will run our models on the other 4 clusters. We then separate each cluster's data into a training and testing set, and then run each model on the training set and subsequently evaluate it on the test data. 

For the KNN, we first created a base model using k equals the square root of the rows of the training dataset. While this model runs fine, we quickly realized that it has a low accuracy and Kappa. One such reason is that the data is heavily skewed. To address this concern, we decided to try lower k values until finding the best-performing models for each cluster based on accuracy, Kappa, and type I & II errors.

For the ANN, we used a learning rate of 0.01, which is the amount that the weights are updated during training. Setting the learning rate very low was very computationally expensive and caused our model to run very slowly. However, we also did not want to set it too high as this would cause the model to converge too quickly. Additionally, we set the threshold to be 0.05, an increase from the default 0.01 so that the model would run faster. This means that the error only needs to change by 0.05 until the model stops optimizing. Also, we set a boundary for the stepmax so that it stops converging after a set amount of iterations so our model does not fail to converge. Additionally, adjusting the number of hidden layers and neurons allows us to make improvements to the model. I also varied the algorithm used to calculate the neural network.

For the Logistic Regression, we first created a base model then removed all variables that contain only missing value (NA) and those that are not significant (P values that approximately equal to 1) according to different clusters. Specifically, we added interactions to the model in cluster 3 to improve accuracy rate. For example, jobunemployed is interacted with emp.var.rate; educationprofessional.course is interacted with emp.var.rate. This is because people may increase or decrease their demand significantly in purchasing term of deposit according to employment variation rate. In another case, jobadmin is interacted with contacttelephone; jobblue.collar is interacted with contacttelephone. This is because administrators are likely to be too busy to be reached while blue collar workers may be more likely to pick up the phone. 
For the rest of the clusters, logistic regression model is problematic and inefficient for prediction because the data only has minimal difference between each other in one cluster.


We also do not want to include the outcome variable in the testing data for the logistic regression and neural network so that it doesn't overperform on the test data.

When evaluating the model, we want to look at certain parameters. Sensitivity tells us of the people who would have been a success, how many did we call, so ideally, we want this number to be high. Additionally, we want the positive prediction rate to be higher than our baseline.

### Cluster 2
```{r, cache=TRUE}
set.seed(12345)
test_set2 <- sample(1:nrow(cluster_2), 2500)
tele_train_labels_2 <- cluster_2[-test_set2, "yyes"]
tele_test_labels_2 <- cluster_2[test_set2, "yyes"]
tele_train_2 <- cluster_2[-test_set2,]
tele_test_2 <- cluster_2[test_set2,]

#KNN
#The model commented out below is the base model
#teleknn_model2 <- knn(train = tele_train_2, test = tele_test_2, cl = tele_train_labels2, k = sqrt(nrow(tele_train_2)))

#The model below is the best-performing model based on accuracy, Kappa, and type I & II errors.
teleknn_model2_improved <- knn(train = tele_train_2, test = tele_test_2, cl = tele_train_labels_2, k = 5)

#The cross table and the confusion matrix serves to analyze the KNN model
CrossTable(x = tele_test_labels_2, y = teleknn_model2_improved, prop.chisq = FALSE)
confusionMatrix(as.factor(teleknn_model2_improved), as.factor(tele_test_labels_2), positive = "1")

#ANN

tele_train_2$yyes <- ifelse(tele_ann_train_2$yyes > 0, .9, .1) #only for ANN & logistic
tele_ann_test_2 <- cluster_2[test_set2,-match("yyes",names(cluster_2))]

teleann_model_2 <- neuralnet(formula = yyes ~ ., data = tele_train_2, hidden=c(2), stepmax=10^100, threshold=0.03)
 #threshold=0.05, stepmax=10^10, learningrate=0.01)
 plot(teleann_model_2)
 model_results <- compute(teleann_model_2, tele_ann_test_2)
predicted_strength <- model_results$net.result
 model_results <- ifelse(predicted_strength>=threshold, 1,0) #convert thresholds
 cor(predicted_strength, tele_test_labels_2)

 CrossTable(x = tele_test_labels_2, y = model_results, prop.chisq = FALSE)
confusionMatrix(as.factor(model_results), as.factor(tele_test_labels_2), positive = "1")


#Logistic
threshold<-0.5
tele_train_log_2 <- cluster_2[-test_set2, ]
tele_test_log_2 <- cluster_2[test_set2, ]
tele_train_log_2$yyes <- NULL
tele_test_log_2$yyes <- NULL

#Now the response (aka Labels)
tele_train_labels_2 <- cluster_2[-test_set2, "yyes"]
tele_test_labels_2 <- as.factor(cluster_2[test_set2, "yyes"])

tele_train_log_2$y <- tele_train_labels_2

#tele_train_log_2 <- cluster_2[-test_set2,-match('yyes',names(cluster_2))]
#tele_test_log_2 <- cluster_2[test_set2,-match('yyes',names(cluster_2))]
#tele_train_log_2$y <- tele_train_labels_2

tele_log_model_2 <- glm(y~.-jobunknown-loanunknown-monthjun-monthmar-monthmay-monthnov-monthoct- monthsep-poutcomenonexistent-emp.var.rate -emp.var.rate -cons.price.idx-cons.conf.idx-nr.employed -pdaysdummy-maritalunknown-defaultyes-defaultunknown-cluster-poutcomesuccess-day_of_weektue-monthdec+contacttelephone*day_of_weekwed+jobhousemaid*day_of_weekwed, data =tele_train_log_2, family = "binomial")
summary(tele_log_model_2)

predict_values_2 <- predict(tele_log_model_2, newdata=tele_test_log_2, type="response")
modpred_2 <- ifelse(predict_values_2 <= threshold, 0, 1)

CrossTable(x = as.factor(tele_test_labels_2), y = as.factor(modpred_2), prop.chisq=FALSE)
confusionMatrix(as.factor(modpred_2), as.factor(tele_test_labels_2), positive = "1")

str(as.factor(modpred_2))
str(as.factor(tele_test_labels_2))
```

### Cluster 3


```{r, cache=TRUE}
set.seed(12345)
test_set3 <- sample(1:nrow(cluster_3), 1500)
tele_train_labels_3 <- cluster_3[-test_set3, "yyes"]
tele_test_labels_3 <- cluster_3[test_set3, "yyes"]
tele_train_3 <- cluster_3[-test_set3,]
tele_test_3 <- cluster_3[test_set3,]

#KNN
#The model commented out below is the base model
#teleknn_model3 <- knn(train = tele_train_3, test = tele_test_3, cl = tele_train_labels_3, k = sqrt(nrow(tele_train_3)))

#The model below is the best-performing model based on accuracy, Kappa, and type I & II errors.
teleknn_model3_improved <- knn(train = tele_train_3, test = tele_test_3, cl = tele_train_labels_3, k = 5)

#The cross table and the confusion matrix serves to analyze the KNN model
CrossTable(x = tele_test_labels_3, y = teleknn_model3_improved, prop.chisq = FALSE)
confusionMatrix(as.factor(teleknn_model3_improved), as.factor(tele_test_labels3), positive = "1")

#ANN


tele_ann_train_3$yyes <- ifelse(tele_ann_train_3$yyes > 0, .9, .1) #only for ANN & logistic
teleann_test_3 <- cluster_3[test_set3,-match("yyes",names(cluster_3))]

teleann_model_3 <- neuralnet(formula = yyes ~ ., data = tele_train_3, hidden=c(1), threshold=0.03, stepmax=10^10, learningrate=0.01)
plot(teleann_model_3)
model_results <- compute(teleann_model_3, teleann_test_3)
predicted_strength <- model_results$net.result
model_results <- ifelse(predicted_strength>=threshold, 1,0) #convert thresholds
cor(predicted_strength, tele_test_labels_3)
CrossTable(x = tele_test_labels_3, y = model_results, prop.chisq = FALSE)
confusionMatrix(as.factor(model_results), as.factor(tele_test_labels_3), positive = "1")


#Logistic
tele_train_log_3 <- cluster_3[-test_set3,-match('yyes',names(cluster_3))]
tele_test_log_3 <- cluster_3[test_set3,-match('yyes',names(cluster_3))]
tele_train_log_3$y <- tele_train_labels_3

tele_log_model_3 <- glm(y~.-jobunknown- maritalmarried - educationilliterate -defaultyes -loanunknown-cluster+jobunemployed*emp.var.rate + educationprofessional.course*emp.var.rate + jobadmin.*contacttelephone + jobblue.collar*contacttelephone + jobstudent*educationuniversity.degree+jobadmin.*day_of_weekmon+jobblue.collar*day_of_weekmon+jobentrepreneur*day_of_weekmon +jobstudent*day_of_weekmon+ jobstudent*monthjun, data = tele_train_log_3, family = "binomial")
summary(tele_log_model_3)

predict_values_3 <- predict(tele_log_model_3, newdata=tele_test_log_3, type="response")
modpred_3 <- as.factor(ifelse(predict_values_3 <= threshold, 0, 1))

CrossTable(x = tele_test_labels_3, y = modpred_3, prop.chisq=FALSE)
confusionMatrix(modpred_3, as.factor(tele_test_labels_3), positive = "1")
```

### Cluster 4
```{r}
set.seed(12345)
test_set4 <- sample(1:nrow(cluster_4), 1500)
tele_train_labels_4 <- cluster_4[-test_set4, "yyes"]
tele_test_labels_4 <- cluster_4[test_set4, "yyes"]
tele_train_4 <- cluster_4[-test_set4,]
tele_test_4 <- cluster_4[test_set4,]

#KNN
#The model commented out below is the base model
#teleknn_model4 <- knn(train = tele_train_4, test = tele_test_4, cl = tele_train_labels_4, k = sqrt(nrow(tele_train_4)))

#The model below is the best-performing model based on accuracy, Kappa, and type I & II errors.
teleknn_model4_improved <- knn(train = tele_train_4, test = tele_test_4, cl = tele_train_labels_4, k = 1)

#The cross table and the confusion matrix serves to analyze the KNN model
CrossTable(x = tele_test_labels_4, y = teleknn_model4_improved, prop.chisq = FALSE)
confusionMatrix(as.factor(teleknn_model4_improved), as.factor(tele_test_labels_4), positive = "1")


#ANN

tele_ann_train_4$yyes <- ifelse(tele_ann_train_4$yyes > 0, .9, .1) #only for ANN & logistic
tele_ann_test_4 <- cluster_4[test_set4,-match("yyes",names(cluster_4))]

teleann_model_4 <- neuralnet(formula = yyes ~ ., data = tele_train_4, hidden=c(2,2), threshold=0.03, stepmax=10^100, learningrate=0.01)
plot(teleann_model_4)
model_results <- compute(teleann_model_4, tele_ann_test_4)
predicted_strength <- model_results$net.result
model_results <- ifelse(predicted_strength>=threshold, 1,0) #convert thresholds
cor(predicted_strength, tele_test_labels_4)
CrossTable(x = tele_test_labels_4, y = model_results, prop.chisq = FALSE)
confusionMatrix(as.factor(model_results), as.factor(tele_test_labels_4), positive = "1")

#Logistic
tele_train_log_4 <- cluster_4[-test_set4,-match('yyes',names(cluster_4))]
tele_test_log_4 <- cluster_4[test_set4,-match('yyes',names(cluster_4))]
tele_train_log_4$y <- tele_train_labels_4

tele_log_model_4 <- glm(y~.-jobhousemaid-jobmanagement-jobself.employed-jobstudent-jobunemployed -maritalunknown -educationilliterate-defaultyes-loanunknown-monthmar-monthsep-monthoct-monthaug-poutcomenonexistent -educationuniversity.degree + educationprofessional.course*loanyes -poutcomesuccess-cons.price.idx -cons.conf.idx -nr.employed-pdaysdummy-cluster-previous, data = tele_train_log_4,family = "binomial")
summary(tele_log_model_4)

predict_values_4 <- predict(tele_log_model_4, newdata=tele_test_log_4, type="response")
modpred_4 <- as.factor(ifelse(predict_values_4 <= threshold, 0, 1))

CrossTable(x = as.factor(tele_test_labels_4), y = modpred_4, prop.chisq=FALSE)
confusionMatrix(modpred_4, as.factor(tele_test_labels_4), positive = "1")
```

### Cluster 5
```{r}
set.seed(12345)
test_set5 <- sample(1:nrow(cluster_5), 2000)
tele_train_labels_5 <- cluster_5[-test_set5, "yyes"]
tele_test_labels_5 <- cluster_5[test_set5, "yyes"]
tele_train_5 <- cluster_5[-test_set5,]
tele_test_5 <- cluster_5[test_set5,]

#KNN
#The model commented out below is the base model
#teleknn_model5 <- knn(train = tele_train_5, test = tele_test_5, cl = tele_train_labels5, k = sqrt(nrow(tele_train_5)))

#The model below is the best-performing model based on accuracy, Kappa, and type I & II errors.
teleknn_model5_improved <- knn(train = tele_train_5, test = tele_test_5, cl = tele_train_labels_5, k = 1)

#The cross table and the confusion matrix serves to analyze the KNN model
CrossTable(x = tele_test_labels_5, y = teleknn_model5_improved, prop.chisq = FALSE)
confusionMatrix(as.factor(teleknn_model5_improved), as.factor(tele_test_labels_5), positive = "1")


#ANN


tele_ann_train_5$yyes <- ifelse(tele_ann_train_5$yyes > 0, .9, .1) #only for ANN & logistic
tele_ann_test_5 <- cluster_5[test_set5,-match("yyes",names(cluster_5))]

teleann_model_5 <- neuralnet(formula = yyes ~ ., data = tele_train_5, hidden=c(3,2), threshold=0.03, stepmax=10^100,algorithm = "backprop")
plot(teleann_model_5)
model_results <- compute(teleann_model_5, tele_ann_test_5)
predicted_strength <- model_results$net.result
model_results <- ifelse(predicted_strength>=threshold, 1,0) #convert thresholds
cor(predicted_strength, tele_test_labels_5)
CrossTable(x = tele_test_labels_5, y = model_results, prop.chisq = FALSE)
confusionMatrix(as.factor(model_results), as.factor(tele_test_labels_5), positive = "1")

#Logistic
tele_train_log_5 <- cluster_5[-test_set5,-match('yyes',names(cluster_5))]
tele_test_log_5 <- cluster_5[test_set5,-match('yyes',names(cluster_5))]
tele_train_log_5$y <- tele_train_labels_5

tele_log_model_5 <- glm(y~.-jobunknown - educationilliterate -defaultyes -loanunknown-contacttelephone-monthmar-monthoct-monthsep--poutcomenonexistent-poutcomesuccess- -cons.conf.idx-nr.employed -pdaysdummy-cluster-poutcomenonexistent-cons.conf.idx -housingyes-monthaug-monthdec-monthjul-monthjun-monthmay-monthnov-emp.var.rate-cons.price.idx-educationhigh.school-previous+jobunemployed*campaign, data = tele_train_log_5, family = "binomial")

summary(tele_log_model_5)
predict_values_5 <- predict(tele_log_model_5, newdata=tele_test_log_5, type="response")
modpred_5 <- as.factor(ifelse(predict_values_5 <= threshold, 0, 1))

CrossTable(x = as.factor(tele_test_labels_5), y = as.factor(modpred_5), prop.chisq=FALSE)
confusionMatrix(modpred_5, as.factor(tele_test_labels_5), positive = "1")
```


#Voting Model
```{r}





```


